```{r create_basic_documentation, echo=TRUE}
# Before anything else, set global options
opts_chunk$set(echo=TRUE, cache=FALSE, error=TRUE)

doc <- NULL
doc$run.date <- date()
doc$version <- system(' git rev-parse HEAD', intern=TRUE)
doc$author <- "Steve Simon (KUMC)"
doc$maintainer <- "Steve Simon (KUMC)"
doc$assistants <- "Dan Connolly"
```


analyze_lasso.Rmd
=================
For context, see [485].

[485]: https://informatics.gpcnetwork.org/trac/Project/ticket/485
[bc_qa]: https://bitbucket.org/gpcnetwork/bc_qa

This program analyzes a case-control data set. It produces some simple
tables and graphs based on the lasso and/or elastic net models.

A summary of how the data were originally collected appears in 
extract_case_control.Rmd.

A companion program, extract_case_control, produces the data set
used by this program. The data files from this program are used
by display_lasso.Rmd.

This program was run on `r doc$date` using version `r doc$version`.
The original author is `r doc$author`. `r doc$maintainer`
is currently maintaining and enhancing this program
with the assistance of `r doc$assistants`.


```{r load_required_libraries, echo=TRUE}
save.image("backup.RData")
rm(list=ls())

# Don't wrap so much
options(width=90)

# load the required libraries
library("reshape2")
library("glmnet")
library("knitr")
library("Matrix")

# Load the case-control data sets
load("case_control_data.RData")

# Document when this program started.

qc <- TRUE
start_time <- Sys.time()
if (qc) {
  cat("\n\nProgram started at ")
  print(start_time)
  cat("\n\nQuality check: Are we in the correct directory? ")
  print(getwd())
}

# Here are some utility functions.

source("create_utility_functions.R")

```

Below, we include only those codes that appear reasonably often
among the cases.

```{r include_only_popular_icd9_codes, timer=TRUE}
cutoff <- 100
n1 <- length(unique(lb$dx_label))
lc <- lb[lb$dx_count >= cutoff, ]
rm(lb)
n2 <- length(unique(lc$dx_label))
```

The initial data set has `r n1` unique ICD9 codes. After eliminating
the codes that occur less than `r cutoff` times among the cases,
there are `r n2` unique ICD9 codes left.

```{r experiment_with_sparse_matrices, timer=TRUE}
# This is a work in progress. If the number of variables gets
# very large, you may need to switch from the standard
# matrix storage to sparse matrices.
create_sparse_matrix <- function(tst) {
  irow <- factor(tst$patient_num)[!is.na(tst$dx_label)]
  jcol <- factor(tst$dx_label)[!is.na(tst$dx_label)]
  o <- order(tst$patient_num)
  pg <- tst[o, c("patient_num", "gp")]
  pg <- pg[!duplicated(pg$patient_num), ]
  row_names <- sort(as.character(unique(irow)))
  column_names <- sort(as.character(unique(jcol)))
  sm <- sparseMatrix(i=as.numeric(irow), j=as.numeric(jcol), x=1, use.last.ij=TRUE)
  dimnames(sm) <- list(row_names, column_names)
  return(list(pg=pg, sm=sm))
}

create_traditional_matrix <- function(tst) {
  tm <- dcast(tst ,patient_num + gp ~ dx_label,length)
  pg <- tm[, 1:2]
  return(list(pg=pg, tm=tm[, -(1:2)]))
}

quality_check <- FALSE

# The time to run a quality check is prohibitive when the number of
# columns in the matrix is in the thousands.

if (quality_check) {
  print(Sys.time())
  tst1 <- create_sparse_matrix(lc)
  print(Sys.time())
  tst2 <- create_traditional_matrix(lc)
  print(Sys.time())
  print(format(object.size(tst1), "auto"))
  print(format(object.size(tst2), "auto"))
  sample_list <- sample(dimnames(tst1$sm)[[2]],5)
  for (v in sample_list) {
    print(v)
    print(table(tst1$pg$gp,tst1$sm[, v]))
    print(table(tst2$gp, tst2[, v]))
  }
}
```

Optionally, create training and test data sets.

```{r create_training_and_test_data_sets}
proportion_training <- 0.7
unique_patients <- sort(unique(lc[, "patient_num"]))
select <- sample(c("Train","Test"), length(unique_patients), replace=TRUE,
                 prob=c(proportion_training, 1-proportion_training))
if (qc) {print_random_rows(select)}
ld <- merge(lc, data.frame(patient_num=unique_patients, select=select))
le <- ld[ld$select=="Train", ]
```

Now, run a lasso/elastic net model for each control group.

```{r store_lasso_models, timer=TRUE}
all_models <- NULL
all_cv <- NULL
for (ic in i_control) {
  pc1 <- create_sparse_matrix(le[le$gp %in% c(i_case, ic), ])
  iv_matrix <- pc1$sm
  dv_vector <- as.numeric(pc1$pg[,"gp"]==i_case)
  en <- glmnet(
    x=iv_matrix, alpha=0.5, 
    standardize=FALSE, lower.limits=0, 
    y=dv_vector,
    family="binomial")
  all_models[[ic]] <- en
  cv <- cv.glmnet(
    x=iv_matrix, alpha=0.5,
    standardize=FALSE, lower.limits=0, 
    y=dv_vector,
    lambda=en$lambda,
    family="binomial",
    type.measure="class")
  all_cv[[ic]] <- cv
}
```

Store everything for later use.

```{r save-everything, timer=TRUE}
save.image(file="analyze_lasso.RData")
```

Well done. Here is how long everything took.

```{r display_timing_log}
if (qc) {
  cat("Program began at ")
  cat(as.character(start_time))
  cat("\nProgram ended at ")
  cat(as.character(Sys.time()))
  cat("\n\n")
  tm <- read.table("timing_log.txt")$V1
  cat(paste(tm, collapse="\n"))
}
```
