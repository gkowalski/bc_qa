```{r create_basic_documentation, echo=TRUE}
# Before anything else, set global options
opts_chunk$set(echo=TRUE, cache=TRUE, error=TRUE)

doc <- NULL
doc$run.date <- date()
doc$version <- system(' git rev-parse HEAD', intern=TRUE)
doc$author <- "Steve Simon (KUMC)"
doc$maintainer <- "Steve Simon (KUMC)"
doc$assistants <- "Dan Connolly"
```


Case-control
============
For context, see [485].

[485]: https://informatics.gpcnetwork.org/trac/Project/ticket/485
[bc_qa]: https://bitbucket.org/gpcnetwork/bc_qa

This program takes a model and evaluates it on patients. It stores the data and some
intermediate files in an RData file.


Currently, this program takes the model developed by display_lasso.Rmd,
but it can be adapted for models from other programs without too much
difficulty.

Here's a rough outline of how the program works.

1. Get a list of all the variables included in the model. 
2. Get a list of patients.
3. Find any records for these patients that have variables in the model.
4. Calculate a prediction based on those variables.
5. Assess the quality of that prediction.

This program was run on `r doc$date` using version `r doc$version`.
The original author is `r doc$author`. `r doc$maintainer`
is currently maintaining and enhancing this program
with the assistance of `r doc$assistants`.


```{r run_preliminaries, cache=FALSE}

# Backup image (just in case) and then start with a blank slate.

save.image("backup.RData")
rm(list=ls())

# Set qc option, if TRUE, print various intermediate values and quality checks.

qc <- TRUE

# Document when this program started.

start_time <- Sys.time()
if (qc) {
  cat("\n\nProgram started at ")
  print(start_time)
}

# load required libraries.

library("ROracle")
library("RSQLite")
library("knitr")

# Check to see if you are in the proper subdirectory.

if (qc) {
  cat("\n\nQuality check: Are we in the correct directory?\n")
  print(getwd())
}

# Control wrapping

options(width=90)

# Here are some functions needed in this program.

source("create_utility_functions.R")

```

Set up an archive for intermediate data files.

```{r setup_archive_storage, timer=TRUE}

# This program uses many different data frames. Data frames associated
# with different databases will typically start with the same letter.
#   p: individual patient ids for each disease group
#   i: data from additional i2b2 queries
#   c: data from the CDM
#
# Most of these are intermediate data frames.
# As a quality check and to test new code, I will store the intermediate
# data frames in a list called archive

if (exists(arc)) rm(arc)

```

Read the model. Get code_key to link to original names.

```{r read_model, timer=TRUE}
load(file="display_lasso.RData")
load(file="case_control_data.RData")
ma <- merge(x=lb, y=lasso_model, all=FALSE, by.x="dx_label", by.y="lb")
save.image("evaluate_model.RData")
if (qc) {
  print_random_rows(ma)
}
# remove everything except first.
o <- order(ma$patient_num, ma$dx_label, ma$observation_date)
mb <- ma[o, ]
n <- dim(mb)[1]
mb$same_patient <- c(0,as.numeric(mb$patient_num[-1]==mb$patient_num[-n]))
mb$same_dx_label <- c(0,as.numeric(mb$dx_label[-1]==mb$dx_label[-n]))
mb$duplicates <- pmin(mb$same_patient, mb$same_dx_label)
head(mb[,c(1,2,7:9)],20)
keep_list <- c("dx_label","patient_num","gp","dx_count","observation_date","co")
mc <- mb[!mb$duplicates, keep_list]
o <- order(mc$patient_num, mc$observation_date)
mc <- mc[o, ]
head(mc,200)
md <- aggregate(mc$co, mc[, c("patient_num", "gp")], sum)
print_random_rows(md)
names(md)[3] <- c("co")
baseline_probability <- 0.1
baseline_odds <- baseline_probability / (1-baseline_probability)
updated_odds <- baseline_odds * exp(md$co)
md$updated_probability <- updated_odds / (1+updated_odds)
plot(factor(md$gp), md$updated_probability)
tapply(md$updated_probability,md$gp,function(x) {sum(x>0.9)})
```

Now let's peek at random cases.

```{r peek_at_random}
library("chron")
random_patients <- sample(md$patient_num, 20)
for (p in random_patients) {
  print(p)
  sb <- mc[mc$patient_num==p, ]
  print(sb)
  cumulative_co <- cumsum(sb$co)
  plot(sb$observation_date, cumulative_co,type="s")
}
```

```{r save_everything}
save.image(file="evaluate_model.RData")
```

Well done. Here is how long everything took.

```{r display_timing_log}
if (qc) {
  cat("Program began at ")
  cat(as.character(start_time))
  cat("\nProgram ended at ")
  cat(as.character(Sys.time()))
  cat("\n\n")
  tm <- read.table("timing_log.txt")$V1
  cat(paste(tm, collapse="\n"))
}
```
