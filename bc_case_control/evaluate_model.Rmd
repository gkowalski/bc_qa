```{r create_basic_documentation, echo=TRUE}
# Before anything else, set global options
opts_chunk$set(echo=TRUE, cache=FALSE, error=TRUE)

doc <- NULL
doc$run.date <- date()
doc$version <- system(' git rev-parse HEAD', intern=TRUE)
doc$author <- "Steve Simon (KUMC)"
doc$maintainer <- "Steve Simon (KUMC)"
doc$assistants <- "Dan Connolly"
```


Case-control
============
For context, see [485].

[485]: https://informatics.gpcnetwork.org/trac/Project/ticket/485
[bc_qa]: https://bitbucket.org/gpcnetwork/bc_qa

This program takes a model and evaluates it on patients. It stores the data and some
intermediate files in an RData file.


Currently, this program takes the model developed by display_lasso.Rmd,
but it can be adapted for models from other programs without too much
difficulty.

Here's a rough outline of how the program works.

1. Get a list of all the variables included in the model. 
2. Get a list of patients.
3. Find any records for these patients that have variables in the model.
4. Calculate a prediction based on those variables.
5. Assess the quality of that prediction.

This program was run on `r doc$date` using version `r doc$version`.
The original author is `r doc$author`. `r doc$maintainer`
is currently maintaining and enhancing this program
with the assistance of `r doc$assistants`.


```{r run_preliminaries, cache=FALSE}

# Backup image (just in case) and then start with a blank slate.

save.image("backup.RData")
rm(list=ls())

# Set qc option, if TRUE, print various intermediate values and quality checks.

qc <- TRUE

# Document when this program started.

start_time <- Sys.time()
if (qc) {
  cat("\n\nProgram started at ")
  print(start_time)
}

# load required libraries.

library("ROracle")
library("RSQLite")
library("knitr")

# Check to see if you are in the proper subdirectory.

if (qc) {
  cat("\n\nQuality check: Are we in the correct directory?\n")
  print(getwd())
}

# Control wrapping

options(width=90)

# Here are some functions needed in this program.

source("create_utility_functions.R")

```

Set up an archive for intermediate data files.

```{r setup_archive_storage, timer=TRUE}

# This program uses many different data frames. Data frames associated
# with different databases will typically start with the same letter.
#   p: individual patient ids for each disease group
#   i: data from additional i2b2 queries
#   c: data from the CDM
#
# Most of these are intermediate data frames.
# As a quality check and to test new code, I will store the intermediate
# data frames in a list called archive

if (exists("arc")) rm(arc)

```

Read the model. Get code_key to link to original names.

```{r read_model, timer=TRUE}
load(file="display_lasso.RData")
load(file="case_control_data.RData")
ma <- merge(x=lb, y=lasso_model, all=FALSE, by.x="dx_label", by.y="dx")
rm(lb)
save.image("evaluate_model.RData")
if (qc) {
  print_random_rows(ma)
}
# remove everything except first.
o <- order(ma$patient_num, ma$dx_label, ma$observation_date)
mb <- ma[o, ]
n <- dim(mb)[1]
mb$same_patient <- c(0,as.numeric(mb$patient_num[-1]==mb$patient_num[-n]))
mb$same_dx_label <- c(0,as.numeric(mb$dx_label[-1]==mb$dx_label[-n]))
mb$duplicates <- pmin(mb$same_patient, mb$same_dx_label)
keep_list <- c("dx_label","patient_num","gp","dx_count","observation_date","co")
mc <- mb[!mb$duplicates, keep_list]
o <- order(mc$patient_num, mc$observation_date)
mc <- mc[o, ]
md <- aggregate(mc$co, mc[, c("patient_num", "gp")], sum)
if (qc) print_random_rows(md)
names(md)[3] <- c("co")
baseline_probability <- 0.1
baseline_odds <- baseline_probability / (1-baseline_probability)
updated_odds <- baseline_odds * exp(md$co)
md$updated_probability <- updated_odds / (1+updated_odds)
plot(factor(md$gp), md$updated_probability)
tapply(md$updated_probability,md$gp,function(x) {sum(x>0.9)})
```

Now let's peek at random cases.

```{r peek_at_random, fig.width=8, fig.height=5}
library("chron")
random_patients <- sample(md$patient_num, 200)
for (p in random_patients) {
  sb <- mc[mc$patient_num==p, ]
  baseline_probability=0.1
  baseline_odds <- baseline_probability / (1-baseline_probability)
  cumulative_co <- cumsum(sb$co)
  cumulative_odds <- exp(cumulative_co)*baseline_odds
  sb$cumulative_probability <- round(cumulative_odds / (1+cumulative_odds), 2)
  sb$days <- round(as.numeric(sb$observation_date - sb$observation_date[1]) / (24*60*60), 1)
  n <- dim(sb)[1]
  par(mfrow=c(1,2))
  par(mar=c(2.6, 2.6, 2.6, 0.6))
  plot(sb$cumulative_probability, sb$days, type="S", xlim=c(0,1), ylim=c(sb$days[n]+30, -30))
  segments(0.1, -30, 0.1, 0)
  segments(0.1, 0, sb$cumulative_probability[1], 0)
  segments(sb$cumulative_probability[n], sb$days[n], sb$cumulative_probability[n], sb$days[n]+30)
  title(paste(sb$patient_num[1], ", ", sb$gp[1], sep=""))
  par(mar=c(2.6,0,2.6,0))
  plot(sb$cumulative_probability, sb$days, type="n", xlim=c(0,1), ylim=c(sb$days[n]+30, -30), axes=FALSE)
  title(paste("First event on ", sb$observation_date[1], sep=""))
  text(0, sb$days, sb$dx_label, cex=1, adj=0)
  cat(paste(sb[1, c("patient_num", "gp")], collapse=", "))
  cat("\n")
  print(sb[, c("days", "co", "cumulative_probability", "dx_label")])
}
```

```{r save_everything}
save.image(file="evaluate_model.RData")
```

Well done. Here is how long everything took.

```{r display_timing_log}
if (qc) {
  cat("Program began at ")
  cat(as.character(start_time))
  cat("\nProgram ended at ")
  cat(as.character(Sys.time()))
  cat("\n\n")
  tm <- read.table("timing_log.txt")$V1
  cat(paste(tm, collapse="\n"))
}
```
