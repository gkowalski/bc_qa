```{r create_basic_documentation, echo=TRUE}
doc <- NULL
doc$run.date <- date()
doc$version <- system(' git rev-parse HEAD', intern=TRUE)
doc$author <- "Steve Simon (KUMC)"
doc$maintainer <- "Steve Simon (KUMC)"
doc$assistants <- "Dan Connolly"
```


Case-control
============
For context, see [485].

[485]: https://informatics.gpcnetwork.org/trac/Project/ticket/485
[bc_qa]: https://bitbucket.org/gpcnetwork/bc_qa

This program analyzes a case-control data set. It produces some simple
tables and graphs.

A companion program, extract_case_control, produces the data set
used by this program.

This program was run on `r doc$date` using version `r doc$version`.
The original author is `r doc$author`. `r doc$maintainer`
is currently maintaining and enhancing this program
with the assistance of `r doc$assistants`.


```{r load_required_libraries, echo=TRUE}
library("ggplot2")
save.image("backup.RData")
rm(list=ls())
cat("\n\nQuality check: Are we in the correct directory?")
getwd()
# Don't wrap so much
options(width=90)
# Load the case-control data sets
load("case_control_data.RData")
```

Here's a summary of how the data was selected. We
identified four disease groups in Heron (KUMC's i2b2).

Breast cancer (as identified in the SEER Site Summary),

All other cancers (again from SEER),

Diabetes (ICD9 250 or ICD10 E08-E13), and

Ischemic heart disease (ICD9 410-414.99 or ICD10 I20-I25).

All males were excluded.

The first group represents cases and the other three
represent different control groups. Patients who qualified
for two or more of the above groups were excluded from the
analysis.

There were no date restrictions. In future versions, we may want
to consider some date restrictions and try matching subjects on
age.

We then merged that data with the PCORNET CDM to get 
any ICD9 codes associated with each patient.

Below, we include only those codes that appear reasonably often
among the cases.

```{r include only the popular icd9 codes, echo=TRUE}
cutoff <- 100
n1 <- length(unique(lb$DX))
lb <- lb[lb$dx_count >= cutoff, ]
n2 <- length(unique(lb$DX))
```

The initial data set has `r n1` unique ICD9 codes. After eliminating
the codes that occur less than `r cutoff` times among the cases,
there are `r n2` unique ICD9 codes left.

The event counts are pretty easy to get now. This code
might, however, run better if you do the counting in
SQL instead.

```{r get-event-counts, echo=TRUE}
# Note: table produces a matrix and not a data frame.
ec <- table(lb$dx_label,lb$GP)
```

A simple screen is to look for codes that have a high PPV. That is,
the codes that occur much more often among the cases relative to how
often they occur under the controls.

```{r calculate-ppv, echo=TRUE}
ppv.num <- ec[, rep(i.case, length(i.control))]
ppv.den <- ppv.num + ec[, i.control]
ppv   <- round(100*ppv.num / ppv.den)
dimnames(ppv)[[2]] <- i.control 
high_ppv <- apply(ppv , 1, min)
o <- rev(order(high_ppv))
ppv[o, ]
```

Now let's display the data using odds ratios.

```{r display_or, echo=TRUE}
su <- merge(st, data.frame(PATIENT_NUM=unique(lb$PATIENT_NUM)))
disease_counts <- table(su$GP)
matrix_counts <- matrix(disease_counts,nrow=dim(ec)[[1]],ncol=dim(ec)[[2]],byrow=TRUE)
ex <- matrix_counts - ec

odds_ratios <- round((ec[,c(1,1,1)]/ex[,c(1,1,1)]) / (ec[,c(2,3,4)]/ex[,c(2,3,4)]),1)
dimnames(odds_ratios)[[2]] <- i.control 
high_or <- apply(odds_ratios , 1, min)
o <- rev(order(high_or))
odds_ratios[o, ]
```

Now let's display the data using sensitivity.

```{r display_sens, echo=TRUE}
sens <- round(100*ec[,1]/(ec[,1]+ex[,1]))
data.frame(sens=rev(sort(sens)))
```

The last step in the preliminary screen is to look at specificity.
It is unclear whether variables with high specificity are
relevant here.

```{r display_spec, echo=TRUE}
spec <- round(100*ex[,2:4]/(ec[,2:4]+ex[,2:4]))
high_spec <- apply(spec, 1, min)
o <- rev(order(high_spec))
spec[o, ]
```

A plot of sensitivity versus specificity might be useful. You should
use the same coordinate system used by the ROC curve plots.

Points in the upper left corner of the plot are best because they have
high sensitivity and high specificity, though you should probably weight
sensitivity more than specificty. These plots are stored separately as
bitmap files.

```{r graph_sens_spec}
m <- 0.25 # Margin for text to separate it from the plotting symbol.
bmp(file="sens_spec%02d.bmp",width=1500,height=2000)
par(mar=c(4.6,4.6,0.1,0.6))
for (i in i.control) {
  plot(100-spec[, i], sens,
     xlim=c(0,100),
     ylim=c(0,120),
     axes=FALSE,
     xlab="False positive rate",
     ylab="True positive rate")
  axis(side=1)
  axis(side=2, at=20*(0:5))
  text(100-spec[, i]-m, sens+m/2,
     names(sens),srt=45,
     cex=2,adj=0)
  text(50,110,i,cex=4)
}
dev.off()
```

Let's pull out the "best" univariate predictor and then pick
the predictor that provides the best incremental improvement
above and beyond the first predictor.

```{r pull-out, echo=TRUE, eval=FALSE}
bp <- names(which(sens==max(sens))) # bp = best predictor
patients_w_best_predictor <- sort(unique(lb[lb$dx_label==bp,"PATIENT_NUM"]))
list_random_rows(patients_w_best_predictor)
remaining_patients <- setdiff(sort(unique(lb$PATIENT_NUM)),patients_w_best_predictor)
list_random_rows(remaining_patients)
lbx <- merge(lb,data.frame(PATIENT_NUM=remaining_patients))
list_random_rows(lbx)
ecx <- table(lbx$dx_label,lbx$GP)
ecx[1:5,]
ec[bp,]
```

```{r save-everything, echo=TRUE}
save.image(file="analyze_sensitivity.RData")
```
